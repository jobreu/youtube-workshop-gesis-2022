---
title: "Automatic Sampling and Analysis of YouTube Data"
subtitle: "Introduction"
author: "Julian Kohne<br />Johannes Breuer<br />M. Rohangis Mohseni"
date: "2022-02-21"
location: "GESIS, online"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["default", "default-fonts", "../workshop.css"]
    nature:
      highlightStyle: "github"
      highlightLines: true
      countIncrementalSlides: false
---

layout: true

```{r setup, include = F}
if (!require(easypackages)) install.packages("easypackages")
library(easypackages)

packages("knitr",
         "rmarkdown",
         "gadenbuie/xaringanExtra",
         "gadenbuie/tweetrmd",
         "hadley/emo",
         prompt = F)

options(htmltools.dir.version = FALSE,
        htmltools.preserve.raw = FALSE)

opts_chunk$set(echo = FALSE,
               fig.align = "center")

xaringanExtra::use_xaringan_extra(c("tile_view", "clipboard"))
xaringanExtra::use_extra_styles(hover_code_line = TRUE,
                                mute_unhighlighted_code = FALSE)
```

<div class="my-footer">
  <div style="float: left;"><span>`r gsub("<br />", ", ", gsub("<br /><br />|<a.+$", "", metadata$author))`</span></div>
  <div style="float: right;"><span>`r metadata$location`, `r metadata$date`</span></div>
  <div style="text-align: center;"><span>`r gsub(".+<br />", " ", metadata$subtitle)`</span></div>
</div>

---

## Goals of this course

After this course you should be able to...
  - automatically collect *YouTube* data
  - process/clean it
  - do some basic (exploratory) analyses of user comments

---

## About us

### Julian Kohne

- M.Sc. in Social Psychology, University of Groningen (NL)

- Scientific Advisor in GESIS presidentidal staff / CSS department
  - Main area: developments of GESIS in the area of digital behavioral data

- PhD Student at University of Ulm / Stanford Social Media Lab
  - Field: Social Psychology
  - Topic: Quantifying interpersonal relationships with chat log data (*WhatsApp*)

[julian.kohne@gesis.org](mailto:julian.kohne@gesis.org), [@JuuuuKoooo](https://twitter.com/JuuuuKoooo), [personal website](https://www.juliankohne.com/)

---

## About us

### Johannes Breuer

.small[
- Senior researcher in the team *Data Augmentation* in the department *Survey Data Curation* at *GESIS*
    - digital trace data for social science research
    - data linking (surveys + digital trace data) 
    
- (Co-) Team leader of the team *Research Data & Methods* at the *Center for Advanced Internet Studies* (CAIS)
    
- Ph.D. in Psychology, University of Cologne  

- Previously worked in several research projects investigating the use and effects of digital media (Cologne, Hohenheim, Münster, Tübingen)  

- Other research interests
    - Computational methods
    - Data management
    - Open science

[johannes.breuer@gesis.org](mailto:johannes.breuer@gesis.org), [@MattEagle09](https://twitter.com/MattEagle09), [personal website](https://www.johannesbreuer.com/)
]

---

## About us

### M. Rohangis Mohseni 

- Postdoctoral researcher (Media Psychology) at TU Ilmenau

- Ph.D. in Psychology, University Osnabrueck

- Ongoing habilitation "sexist online hate speech" `r ji("imp")`

- Other research interests
  - Electronic media effects
  - Moral behavior

[rohangis.mohseni@tu-ilmenau.de](mailto:rohangis.mohseni@tu-ilmenau.de), [@romohseni](https://twitter.com/romohseni)

---

## About you

- What's your name?  

- Where do you work?  

- What is your experience with `R`?

- Why/how do you want to use *YouTube* for your research?


---

## Prerequisites for this course

- Working version of `R` >= 4.0.0 and a recent version of [RStudio](https://rstudio.com/products/rstudio/download/#download)

- Some basic knowledge of `R`  

- Interest in working with *YouTube* data

---

## Workshop Structure & Materials

- The workshop consists of a combination of lectures and hands-on exercises

- Slides and other materials are available at

[https://github.com/jobreu/youtube-workshop-gesis-2022](https://github.com/jobreu/youtube-workshop-gesis-2022)

We also put the PDF versions of the slides and some other materials on the GESIS Ilias repository for this course.

---

## Zoom Etiquette

- If possible, we invite you to turn on your camera (during the lecture and exercise parts); feel free to use a virtual background if you want to

```{r tweet, echo = F}
tweet_embed("https://twitter.com/PhdExhausted/status/1331956737683853318",
            theme = "dark",
            maxwidth = 400,
            align = "center")
```

---

## Zoom Etiquette

- Please mute your microphones unless you are asking a question

- Asking questions:
  - If you have an immediate question, feel free to ask it via video/audio using the "raise hand" function in *Zoom* or via the text chat (private or public)
  - If you have a question that is not urgent and might be interesting for everybody, please wait until the end of the lecture part, then use the "raise hand" function and ask your question via audio/video
  - During the exercises you can also use "raise hand" + audio/video (if you have a question that might be interesting for others as well) or public or private text chat messages to ask questions

- We will also try to provide (one-on-one) "tech support" during the exercises if that is needed (please contact us via the text chat in case you have any technical issues/questions that we can solve)

---

## Preliminaries: Base `R` vs. `tidyverse`

In this course, we will use a mixture of base `R` and `tidyverse` code as Julian prefers base `R`, Johannes prefers the `tidyverse`, and Ro is agnostic.

ICYC, here are some opinions [for](http://varianceexplained.org/r/teach-tidyverse/) and [against](https://blog.ephorie.de/why-i-dont-use-the-tidyverse) using/teaching the `tidyverse`.

--

Johannes' experience with learning and teaching the `tidyverse` is something like this...
```{r tidyverse meme, out.width = "60%"}
include_graphics("./images/tidyverse_vs_baseR_meme.jpg")
```

---

## The `tidyverse`

If you've never seen `tidyverse` code, the most important thing to know is the `%>%` [(pipe) operator](https://magrittr.tidyverse.org/reference/pipe.html). Put briefly, the pipe operator takes an object (which can be the result of a previous function) and pipes it (by default) as the first argument into the next function. This means that `function(arg1 = x)` is equivalent to `x %>% function()`.

It may also be worthwhile to know/remember that `tidyverse` functions normally produce [`tibbles`](https://tibble.tidyverse.org/) which are a special type of dataframe (and most `tidyverse` functions also expect dataframes/tibbles as input to their first argument).

--

If you want a short primer (or need a quick refresher) on the `tidyverse`, you can check out the blog [post by Dominic Royé](https://dominicroye.github.io/en/2020/a-very-short-introduction-to-tidyverse/). For a more in-depth exploration of the `tidyverse`, you can, e.g., have a look at the [workshop by Olivier Gimenez](https://oliviergimenez.github.io/intro_tidyverse/#1). And the book [*R for Data Science*](https://r4ds.had.co.nz/) by Hadley Wickham and Garrett Grolemund (which is available for free online) provides a very comprehensive introduction to the `tidyverse`

---

## Preliminaries: What's in a name?

Another thing you might notice when looking at our code is that we love `r ji("snake")` as much as `r ji("camel")`.

```{r cases, out.width = "75%"}
include_graphics("./images/camel_snake_kebab.jpg")
```
.center[
<small><small>Artwork by [Allison Horst](https://github.com/allisonhorst/stats-illustrations)</small></small>
]
---
# Course schedule

.center[**Monday, February 21st, 2022**]
```{r schedule Wed, echo = F}
schedule <- data.frame(
  "When?" = c("10:00 - 11:00", "11:00 - 11:30", "11:30 - 12:30", "12:30 - 13:30", "13:30 - 15:00", "15:00 - 15:30", "15:30 - 17:00")
  , "What?" = c("Introduction", "<i>Coffee break</i>", "The YouTube API", "<i>Lunch break</i>", "Collecting data with the tuber package for R","<i>Coffee break</i>", "Processing and cleaning user comments (in R)")
  , stringsAsFactors = FALSE
  , check.names = FALSE
)
knitr::kable(
  schedule
  , format = "html"
  , align = "cc"
  , escape = FALSE
)
```

---

## Course schedule

.center[**Tuesday, February 22nd, 2022**]
```{r schedule Thur, echo = F}
sharing_options <- data.frame(
  "When?" = c("09:00 - 10:30", "10:30 - 11:00", "11:00 - 12:00", "12:00 - 13:00", "13:00 - 14:00", "14:00 - 14:30", "14:30 - 16:00")
  , "What?" = c("Basic text analysis of user comments", "<i>Coffee break</i>", "Sentiment analysis of user comments", "<i>Lunch break</i>", "Excursus: Retrieving video subtitles", "<i>Coffee break</i>", "Practice session, questions, and outlook")
  , stringsAsFactors = FALSE
  , check.names = FALSE
)
knitr::kable(
  sharing_options
  , format = "html"
  , align = "cc"
  , escape = FALSE
)
```

---

## Why is *YouTube* relevant?

- Largest / most important online video platform<br /><small>([Alexa Traffic Ranks, 2019](https://www.alexa.com/topsites); [Konijn, Veldhuis, & Plaisier, 2013](https://doi.org/10.1089/cyber.2012.0357))</small>

- Esp. popular among adolescents who use it to watch movies & shows, listen to music, and retrieve information<br /><small>([Feierabend, Plankenhorn, & Rathgeb, 2016](https://www.mpfs.de/studien/kim-studie/2016/))</small>

- For adolescents, *YouTube* partly replaces TV<br /><small>([Defy Media, 2017](http://www.newsroom-publicismedia.fr/wp-content/uploads/2017/06/Defi-media-acumen-Youth_Video_Diet-mai-2017.pdf))</small>

---

## Why is *YouTube* data interesting for research?

- Content producers and users generate huge amounts of data

- Useful for research on media content, communicators, and user interaction

- Data publicly available 

- Relatively easy to retrieve via *YouTube* API

---

## Research Examples

- What do people write (content)?
  - Sexist Online Hate Speech<br /><small>([Doering & Mohseni, 2019a](https://doi.org/10.1080/14680777.2018.1467945), [2019b](https://doi.org/10.1080/08824096.2019.1634533),[2020](https://doi.org/10.5771/2192-4007-2020-1-62); [Thelwall & Mas-Bleda, 2018](https://doi.org/10.1108/AJIM-09-2017-0204); [Wotanis & McMillan, 2014](https://doi.org/10.1080/14680777.2014.882373))</small>

  - Comment characteristics<br /><small>([Thelwall, Sud, & Vis, 2012]( https://doi.org/10.1002/asi.21679))</small>

  - Subtopics, sentiments, & gender differences<br /><small>([Thelwall, 2017](https://doi.org/10.1080/13645579.2017.1381821); [Röchert, Neubaum, Ross, Brachten, & Stieglitz, 2020](https://computationalcommunication.org/ccr/article/view/15/7))</small>

---

## Research Examples

- Who writes it (communicator)?
    - User experiences<br /><small>([Defy Media, 2017](http://www.newsroom-publicismedia.fr/wp-content/uploads/2017/06/Defi-media-acumen-Youth_Video_Diet-mai-2017.pdf); [Lange, 2007](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.170.3808&rep=rep1&type=pdf); [Moor, Heuvelman, & Verleur, 2010](https://doi.org/10.1016/j.chb.2010.05.023); [Oksanen, Hawdon, Holkeri, Naesi, & Raesaenen, 2014](https://doi.org/10.1108/S1537-466120140000018021); [Szostak, 2013](https://journals.mcmaster.ca/mjc/article/view/280); [Yang, Hsu, & Tan, 2010](https://doi.org/10.1089/cyber.2009.0105))</small>
    
    - Radicalization<br /><small>([Ribeiro et al., 2020](https://doi.org/10.1145/3351095.3372879))</small>
    
    - Filter bubble/Structural hierarchy<br /><small>([Kaiser & Rauchfleisch, 2020](https://doi.org/10.1177/2056305120969914); [Rieder et al., 2020](https://doi.org/10.5210/fm.v25i8.10667))

---

## How to collect *YouTube* data

There are many different ways in which data from *YouTube* and other social media can be collected (see [Breuer et al., 2020](https://journals.sagepub.com/doi/10.1177/1461444820924622)):

- Manually (e.g., via copy & paste or manual content analysis)

- Using existing data, such as [*YouNiverse: Large-Scale Channel and Video Metadata from English YouTube*](https://zenodo.org/record/4650046) (also see the accompanying preprint by [Ribeiro & West, 2021](https://arxiv.org/abs/2012.10378))

- Automatically via the *YouTube* API or web scraping

---

## Tools for the Automatic Sampling of *YouTube* Data without `R`

- [YouTube Data Tools](https://tools.digitalmethods.net/netvizz/youtube/)

- [Facepager](https://github.com/strohne/Facepager/wiki)

- [Webometric Analyst](http://lexiurl.wlv.ac.uk/)

Overviews of tools for collecting *YouTube* data

- [YouTube Tools](https://smo-wiki.leibniz-hbi.de/YouTube-Tools) collected by the Leibniz-HBI Social Media Observatory

- [Social Media Research Tookit](https://socialmediadata.org/social-media-research-toolkit/) by the Social Media Lab at Ryerson University

---

# Tools for the Automatic Sampling of *YouTube* Data with `R`

- [`vosonSML`](https://cran.r-project.org/web/packages/vosonSML/) (formerly SocialMediaLab)

- [`VOSONDash`](https://vosonlab.github.io/VOSONDash/)

- [`tuber`](https://cran.r-project.org/web/packages/tuber/)

In this course, we will work with the `tuber` package.

---

## Comparisons of Approaches for Collecting *YouTube* Data

```{r tools table 1, echo = F}
tools <- data.frame(
  "Method" = c("Type", "Platforms", "Collected Features", "Scoping"),
  "Manual Coding" = c("n/a", "All", "Depends on coding scheme", "Depends on coding scheme"),
  "Webometric Analyst" = c("Program", "Win", "Channel Info, Video Info, Comments, Video Search", "100 most recent or all comments"),
  "YouTube Data Tools" = c("Web service", "All", "Channel Info, Video Info, Comments, Video List", "All comments"),
  "tuber" = c("Package for R", "Win, Mac, Linux, Unix", "Channel Info, Video Info, Comments, Subtitles, All searches", "20-100 most recent or all comments")
  , stringsAsFactors = FALSE
  , check.names = FALSE
)
knitr::kable(
  tools
  , format = "html"
  , align = "cc"
  , escape = FALSE
)
```

---

## Pros and Cons of Different Approaches

```{r tools table 2, echo = F}
tools_pc <- data.frame(
  "Method" = c("Need API Key?", "Disadvantages", "Ease of Use", "License", "Example: Dayum Video (22-02-2019, 2pm)"),
  "Manual Coding" = c("No", "Time-consuming", "High", "n/a", "47,163"),
  "Webometric Analyst" = c("Yes", "Only first 5 follow-up comments, no error feedback, undetectable time-outs", "Low", "Free for n/c", "44,828"),
  "YouTube Data Tools" = c("No", "Lacking flexibility, fewer infos", "High", "Open Source", "47,153"),
  "tuber" = c("Yes", "Only first 5 follow-up comments due to bug", "Low", "Open Source", "44,810")
  , stringsAsFactors = FALSE
  , check.names = FALSE
)
knitr::kable(
  tools_pc
  , format = "html"
  , align = "cc"
  , escape = FALSE
)
```

[Dayum Video](https://www.youtube.com/watch?v=DcJFdCmN98s) / [tuber issue](https://github.com/soodoku/tuber/issues/52)

---

## A note on using FOSS

The tools listed before are free and open source software (FOSS). Using FOSS has many advantages (availability, adaptability, etc.). However, one risk associated with using FOSS is that tools are not maintained anymore and, hence, cease to function. After all, people create and maintain these tools in their spare time or as side projects and this work is often not recognized enough (esp. within academia). For this reason it is especially important to acknowledge the work that goes into these tools, e.g., by properly citing them.

.small[
```{r cite-pkg, echo=TRUE}
citation("tuber")
```
]

---

class: center, middle

# Any questions so far?